{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sagemaker Script mode usage (ML - XGboost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Script mode is a very useful technique that lets you easily run your existing code in Amazon SageMaker, with very little change in codes. This time, we will tackle the simple Deep Learning problem (MNIST) with Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use XGboost, but this works the same for other frameworks (TensorFlow, MXNet, PyTorch, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The list of built-in algorithms and its parameters supported by Sagemaker are [Here](https://docs.aws.amazon.com/sagemaker/latest/dg/algos.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, time\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import boto3, sagemaker\n",
    "\n",
    "sess   = sagemaker.Session()\n",
    "bucket = sess.default_bucket()                     \n",
    "prefix = 'xgboost-scriptmode'\n",
    "region = boto3.Session().region_name\n",
    "role = 'arn:aws:iam::570447867175:role/SageMakerNotebookRole' # pass your IAM role name\n",
    "\n",
    "print('Sagemaker version :', sagemaker.__version__)\n",
    "print('Sagemaker session :' sess)\n",
    "print('S3 bucket :' bucket)\n",
    "print('Prefix :' prefix)\n",
    "print('Region selected :' region)\n",
    "print('IAM role :' role)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We will use the same bank deposit dataset as it was in Autopilot example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the direct marketing dataset from UCI's ML Repository.\n",
    "The data is related with direct marketing campaigns of a Portuguese banking institution. The marketing campaigns were based on phone calls. Often, more than one contact to the same client was required, in order to access if the product (bank term deposit) would be ('yes') or not ('no') subscribed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Download Dataset Manually here](https://archive.ics.uci.edu/ml/datasets/bank+marketing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 500)     # Make sure we can see all of the columns\n",
    "pd.set_option('display.max_rows', 50)         # Keep the output on one page\n",
    "\n",
    "# Read data\n",
    "data = pd.read_csv('./bank-additional/bank-additional-full.csv', sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. PreProcess the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove dots in strings and column names\n",
    "data.columns = data.columns.str.replace('\\.', '_')\n",
    "data.replace(to_replace='\\.', value='_', inplace=True, regex=True)\n",
    "\n",
    "# One-hot encode\n",
    "data = pd.get_dummies(data)\n",
    "data = data.drop(['y_no'], axis=1)\n",
    "\n",
    "# Move labels to first column, which is what SM Model Monitor expects\n",
    "data = pd.concat([data['y_yes'], data.drop(['y_yes'], axis=1)], axis=1)\n",
    "\n",
    "# Split into training and validation (95/5)\n",
    "train_data, val_data, _ = np.split(\n",
    "    data.sample(frac=1, random_state=123),\n",
    "    [int(0.95 * len(data)), int(len(data))]\n",
    ")\n",
    "\n",
    "# Save to CSV files\n",
    "train_data.to_csv('training.csv', index=False, header=True, sep=',') # Need to keep column names\n",
    "val_data.to_csv('validation.csv', index=False, header=True, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = \"s3://{}/{}/output/\".format(bucket,prefix)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. You would need your own __.py file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the structure of the python file before loading into the Sagemaker Training job\n",
    "!pygmentize xgb.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, when train the model, you can bring your own scripted algorithm to feed in to the Sagemaker instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data in S3 bucket is utilized and EC2 Instacne is utilized, but only the script is used from local machine to compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = sess.upload_data(path=\"training.csv\", key_prefix=prefix + \"/training\")\n",
    "validation = sess.upload_data(path=\"validation.csv\", key_prefix=prefix + \"/validation\")\n",
    "print(training)\n",
    "print(validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.xgboost import XGBoost\n",
    "\n",
    "xgb_estimator = XGBoost(entry_point='xgb.py',                 # Load your __.py file\n",
    "                          role=role,                          # Your IAM role for Sagemaker\n",
    "                          train_instance_count=1, \n",
    "                          train_instance_type='ml.m4.xlarge',\n",
    "                          framework_version='0.90-2',         # For configuration, please refer to above model link in AWS\n",
    "                          py_version='py3',\n",
    "                          output_path=output,\n",
    "                          hyperparameters={                   # hyperparameters you want to compute. Bring your own once you done grid search\n",
    "                              'max-depth': 5,\n",
    "                              'eval-metric': 'error'\n",
    "                          }\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_estimator.fit({'training':training, 'validation':validation}) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Deploy the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_endpoint_name = prefix+time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "print('endpoint_name :', xgb_endpoint_name) \n",
    "\n",
    "xgb_predictor = xgb_estimator.deploy(\n",
    "                     initial_instance_count=1, \n",
    "                     instance_type='ml.m4.xlarge',\n",
    "                     endpoint_name=xgb_endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Predict samples from the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smrt = boto3.client('sagemaker-runtime')\n",
    "\n",
    "# Predict samples from the validation set\n",
    "payload = val_data[:100].drop(['y_yes'], axis=1) \n",
    "payload = payload.to_csv(header=False, index=False).rstrip()\n",
    "\n",
    "print(payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = smrt.invoke_endpoint(\n",
    "    EndpointName=xgb_endpoint_name,\n",
    "    Body=payload.encode('utf8'),\n",
    "    ContentType='text/csv')\n",
    "\n",
    "print(response['Body'].read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Close the SageMaker Instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make sure we don't get charged after the training is over and endpoint is generated, we have to **delete** the endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.delete_endpoint(endpoint_name=xgb_endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
